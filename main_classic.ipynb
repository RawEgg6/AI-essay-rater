{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a677c795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12976, 4)\n",
      "   essay_id  essay_set                                              essay  \\\n",
      "0         1          1  Dear local newspaper, I think effects computer...   \n",
      "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
      "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
      "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
      "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
      "\n",
      "   domain1_score  \n",
      "0              8  \n",
      "1              9  \n",
      "2              7  \n",
      "3             10  \n",
      "4              8  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('training_set_rel3.tsv', sep='\\t', encoding=\"latin1\")\n",
    "df['essay'] = df['essay'].fillna('')\n",
    "\n",
    "# Keep relevant columns\n",
    "df = df[['essay_id', 'essay_set', 'essay', 'domain1_score']]\n",
    "\n",
    "# Display basic info\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac2ae11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning, dataset shape: (12703, 4)\n"
     ]
    }
   ],
   "source": [
    "# Remove illegible or corrupted essays\n",
    "df = df[~df['essay'].str.contains('illegible|\\\\?\\\\?\\\\?', case=False, na=False)]\n",
    "\n",
    "# Drop any rows with missing text or scores\n",
    "df = df.dropna(subset=['essay', 'domain1_score']).reset_index(drop=True)\n",
    "print(f\"After cleaning, dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c67390b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 1: min=2, max=12\n",
      "Set 2: min=1, max=6\n",
      "Set 3: min=0, max=3\n",
      "Set 4: min=0, max=3\n",
      "Set 5: min=0, max=4\n",
      "Set 6: min=0, max=4\n",
      "Set 7: min=2, max=24\n",
      "Set 8: min=10, max=60\n",
      "==================================================\n",
      "   essay_set  domain1_score  score_scaled\n",
      "0          1              8           0.6\n",
      "1          1              9           0.7\n",
      "2          1              7           0.5\n",
      "3          1             10           0.8\n",
      "4          1              8           0.6\n"
     ]
    }
   ],
   "source": [
    "# Check score ranges per essay set\n",
    "for s in sorted(df['essay_set'].unique()):\n",
    "    min_score = df[df['essay_set'] == s]['domain1_score'].min()\n",
    "    max_score = df[df['essay_set'] == s]['domain1_score'].max()\n",
    "    print(f\"Set {s}: min={min_score}, max={max_score}\")\n",
    "\n",
    "print(\"=\" *50)    \n",
    "\n",
    "# Scale scores to 0-1 range per essay set\n",
    "df['score_scaled'] = df.apply(\n",
    "    lambda x: (x['domain1_score'] - df[df['essay_set'] == x['essay_set']]['domain1_score'].min()) /\n",
    "              (df[df['essay_set'] == x['essay_set']]['domain1_score'].max() -\n",
    "               df[df['essay_set'] == x['essay_set']]['domain1_score'].min()),\n",
    "    axis=1\n",
    ")\n",
    "print(df[['essay_set', 'domain1_score', 'score_scaled']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd168c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  # remove HTML\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # remove special chars\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # remove extra spaces\n",
    "    return text\n",
    "\n",
    "df['essay'] = df['essay'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60ce70f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature matrix shape: (12703, 10003)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# TF-IDF features (unigrams + bigrams)\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    ngram_range=(1, 3),\n",
    "    \n",
    ")\n",
    "X_tfidf = vectorizer.fit_transform(df['essay'])\n",
    "\n",
    "# Simple numeric features\n",
    "df['essay_len'] = df['essay'].apply(len)\n",
    "df['word_count'] = df['essay'].apply(lambda x: len(x.split()))\n",
    "df['avg_word_len'] = df['essay'].apply(lambda x: np.mean([len(w) for w in x.split()]) if len(x.split()) > 0 else 0)\n",
    "\n",
    "numeric_features = df[['essay_len', 'word_count', 'avg_word_len']].values\n",
    "\n",
    "# Combine TF-IDF + numeric\n",
    "from scipy.sparse import csr_matrix\n",
    "X = hstack([X_tfidf, csr_matrix(numeric_features)])\n",
    "y = df['score_scaled'].values\n",
    "\n",
    "print(f\"Final feature matrix shape: {X.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a650602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (10162, 10003), Validation shape: (2541, 10003)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "indices = np.arange(len(df))\n",
    "X_train, X_val, y_train, y_val, idx_train, idx_val = train_test_split(\n",
    "    X, y, indices, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Validation shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6bd92a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ðŸ“Š MODEL PERFORMANCE METRICS\n",
      "==================================================\n",
      "Quadratic Weighted Kappa (QWK): 0.9665\n",
      "Pearson Correlation:            0.7327\n",
      "RÂ² Score:                       0.5369\n",
      "Mean Absolute Error (MAE):      0.1262\n",
      "Root Mean Squared Error (RMSE): 0.1629\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, cohen_kappa_score\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "# Train Ridge Regression\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = ridge.predict(X_val)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "pearson_corr, _ = pearsonr(y_pred, y_val)\n",
    "\n",
    "# Rescale predictions and labels for QWK\n",
    "score_ranges = {\n",
    "    1: (2, 12), 2: (1, 6), 3: (0, 3), 4: (0, 3),\n",
    "    5: (0, 4), 6: (0, 4), 7: (2, 24), 8: (10, 60)\n",
    "}\n",
    "\n",
    "def rescale(scaled, essay_sets):\n",
    "    original = []\n",
    "    for val, s in zip(scaled, essay_sets):\n",
    "        min_score, max_score = score_ranges[s]\n",
    "        orig = val * (max_score - min_score) + min_score\n",
    "        original.append(round(orig))\n",
    "    return np.array(original)\n",
    "\n",
    "# Get essay_set for each validation sample\n",
    "val_essay_sets = df.iloc[idx_val]['essay_set'].values\n",
    "\n",
    "y_pred_orig = rescale(y_pred, val_essay_sets)\n",
    "y_val_orig = rescale(y_val, val_essay_sets)\n",
    "\n",
    "# Calculate QWK\n",
    "qwk = cohen_kappa_score(y_val_orig, y_pred_orig, weights='quadratic')\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"ðŸ“Š MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Quadratic Weighted Kappa (QWK): {qwk:.4f}\")\n",
    "print(f\"Pearson Correlation:            {pearson_corr:.4f}\")\n",
    "print(f\"RÂ² Score:                       {r2:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE):      {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44911971",
   "metadata": {},
   "source": [
    "==================================================\n",
    "ðŸ“Š MODEL PERFORMANCE METRICS 5000, [1,2], Stopwords\n",
    "==================================================\n",
    "Quadratic Weighted Kappa (QWK): 0.9145\n",
    "Pearson Correlation:            0.7135\n",
    "RÂ² Score:                       0.5090\n",
    "Mean Absolute Error (MAE):      0.1296\n",
    "Root Mean Squared Error (RMSE): 0.1677\n",
    "==================================================\n",
    "\n",
    "==================================================\n",
    "ðŸ“Š MODEL PERFORMANCE METRICS 10000, [1,3], \n",
    "==================================================\n",
    "Quadratic Weighted Kappa (QWK): 0.9240\n",
    "Pearson Correlation:            0.7327\n",
    "RÂ² Score:                       0.5369\n",
    "Mean Absolute Error (MAE):      0.1262\n",
    "Root Mean Squared Error (RMSE): 0.1629\n",
    "=================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
